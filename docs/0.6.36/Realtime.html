<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Apache Druid">
<meta name="keywords" content="druid,kafka,database,analytics,streaming,real-time,real time,apache,open source">
<meta name="author" content="Apache Software Foundation">

<title>Druid | </title>

<link rel="alternate" type="application/atom+xml" href="/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">

<link href='//fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/bootstrap-pure.css?v=1.0">
<link rel="stylesheet" href="/css/main.css?v=1.0">
<link rel="stylesheet" href="/css/header.css?v=1.0">
<link rel="stylesheet" href="/css/footer.css?v=1.0">
<link rel="stylesheet" href="/css/syntax.css?v=1.0">
<link rel="stylesheet" href="/css/docs.css?v=1.0">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>

  <body>
    <!-- Start page_header include -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<div class="top-navigator">
  <div class="container">
    <div class="left-cont">
      <a class="logo" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="right-cont">
      <ul class="links">
        <li class=""><a href="/technology">Technology</a></li>
        <li class=""><a href="/use-cases">Use Cases</a></li>
        <li class=""><a href="/druid-powered">Powered By</a></li>
        <li class=""><a href="/docs/latest/design/">Docs</a></li>
        <li class=""><a href="https://druid.apache.org/community/">Community</a></li>
        <li class=" button-link"><a href="/downloads.html">Download</a></li>
      </ul>
    </div>
  </div>
  <div class="action-button menu-icon">
    <span class="fa fa-bars"></span> MENU
  </div>
  <div class="action-button menu-icon-close">
    <span class="fa fa-times"></span> MENU
  </div>
</div>

<script type="text/javascript">
  var $menu = $('.right-cont');
  var $menuIcon = $('.menu-icon');
  var $menuIconClose = $('.menu-icon-close');

  function showMenu() {
    $menu.fadeIn(100);
    $menuIcon.fadeOut(100);
    $menuIconClose.fadeIn(100);
  }

  $menuIcon.click(showMenu);

  function hideMenu() {
    $menu.fadeOut(100);
    $menuIconClose.fadeOut(100);
    $menuIcon.fadeIn(100);
  }

  $menuIconClose.click(hideMenu);

  $(window).resize(function() {
    if ($(window).width() >= 840) {
      $menu.fadeIn(100);
      $menuIcon.fadeOut(100);
      $menuIconClose.fadeOut(100);
    }
    else {
      $menu.fadeOut(100);
      $menuIcon.fadeIn(100);
      $menuIconClose.fadeOut(100);
    }
  });
</script>

<!-- Stop page_header include -->


    <div class="container doc-container">
      
      

      
      <p> Looking for the <a href="/docs/0.14.0-incubating/">latest stable documentation</a>?</p>
      

      <div class="row">
        <div class="col-md-9 doc-content">
          <p>
            <a class="btn btn-default btn-xs visible-xs-inline-block visible-sm-inline-block" href="#toc">Table of Contents</a>
          </p>
          <h1 id="realtime">Realtime</h1>

<p>Realtime nodes provide a realtime index. Data indexed via these nodes is immediately available for querying. Realtime nodes will periodically build segments representing the data they’ve collected over some span of time and transfer these segments off to <a href="Historical.html">Historical</a> nodes. They use ZooKeeper to monitor the transfer and MySQL to store metadata about the transfered segment. Once transfered, segments are forgotten by the Realtime nodes.</p>

<h2 id="quick-start">Quick Start</h2>

<p>Run:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>io.druid.cli.Main server realtime
</code></pre></div>
<p>With the following JVM configuration:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>-server
-Xmx256m
-Duser.timezone=UTC
-Dfile.encoding=UTF-8

druid.host=localhost
druid.service=realtime
druid.port=8083

druid.extensions.coordinates=[&quot;io.druid.extensions:druid-kafka-seven:0.6.36&quot;]


druid.zk.service.host=localhost

druid.db.connector.connectURI=jdbc\:mysql\://localhost\:3306/druid
druid.db.connector.user=druid
druid.db.connector.password=diurd

druid.processing.buffer.sizeBytes=10000000
</code></pre></div>
<p>Note: This setup will not hand off segments to the rest of the cluster.</p>

<h2 id="jvm-configuration">JVM Configuration</h2>

<p>The realtime module uses several of the default modules in <a href="Configuration.html">Configuration</a> and has the following set of configurations as well:</p>

<table><thead>
<tr>
<th>Property</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead><tbody>
<tr>
<td><code>druid.realtime.specFile</code></td>
<td>The file with realtime specifications in it.</td>
<td>none</td>
</tr>
<tr>
<td><code>druid.publish.type</code></td>
<td>Choices:noop, db. After a real-time node completes building a segment after the window period, what does it do with it? For true handoff to occur, this should be set to &quot;db&quot;.</td>
<td>db</td>
</tr>
</tbody></table>

<h3 id="realtime-specfile">Realtime &quot;specFile&quot;</h3>

<p>The property <code>druid.realtime.specFile</code> has the path of a file (absolute or relative path and file name) with realtime specifications in it. This &quot;specFile&quot; should be a JSON Array of JSON objects like the following:</p>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span><span class="p">[</span>
  <span class="p">{</span>
    <span class="nt">&quot;schema&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;dataSource&quot;</span><span class="p">:</span> <span class="s2">&quot;dataSourceName&quot;</span><span class="p">,</span>
      <span class="nt">&quot;aggregators&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;count&quot;</span><span class="p">,</span>
          <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;events&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;doubleSum&quot;</span><span class="p">,</span>
          <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;outColumn&quot;</span><span class="p">,</span>
          <span class="nt">&quot;fieldName&quot;</span><span class="p">:</span> <span class="s2">&quot;inColumn&quot;</span>
        <span class="p">}</span>
      <span class="p">],</span>
      <span class="nt">&quot;indexGranularity&quot;</span><span class="p">:</span> <span class="s2">&quot;minute&quot;</span><span class="p">,</span>
      <span class="nt">&quot;shardSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span>
      <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;maxRowsInMemory&quot;</span><span class="p">:</span> <span class="mi">500000</span><span class="p">,</span>
      <span class="nt">&quot;intermediatePersistPeriod&quot;</span><span class="p">:</span> <span class="s2">&quot;PT10m&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;firehose&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;kafka-0.7.2&quot;</span><span class="p">,</span>
      <span class="nt">&quot;consumerProps&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;zk.connect&quot;</span><span class="p">:</span> <span class="s2">&quot;zk_connect_string&quot;</span><span class="p">,</span>
        <span class="nt">&quot;zk.connectiontimeout.ms&quot;</span><span class="p">:</span> <span class="s2">&quot;15000&quot;</span><span class="p">,</span>
        <span class="nt">&quot;zk.sessiontimeout.ms&quot;</span><span class="p">:</span> <span class="s2">&quot;15000&quot;</span><span class="p">,</span>
        <span class="nt">&quot;zk.synctime.ms&quot;</span><span class="p">:</span> <span class="s2">&quot;5000&quot;</span><span class="p">,</span>
        <span class="nt">&quot;groupid&quot;</span><span class="p">:</span> <span class="s2">&quot;consumer-group&quot;</span><span class="p">,</span>
        <span class="nt">&quot;fetch.size&quot;</span><span class="p">:</span> <span class="s2">&quot;1048586&quot;</span><span class="p">,</span>
        <span class="nt">&quot;autooffset.reset&quot;</span><span class="p">:</span> <span class="s2">&quot;largest&quot;</span><span class="p">,</span>
        <span class="nt">&quot;autocommit.enable&quot;</span><span class="p">:</span> <span class="s2">&quot;false&quot;</span>
      <span class="p">},</span>
      <span class="nt">&quot;feed&quot;</span><span class="p">:</span> <span class="s2">&quot;your_kafka_topic&quot;</span><span class="p">,</span>
      <span class="nt">&quot;parser&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="nt">&quot;timestampSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
          <span class="nt">&quot;column&quot;</span><span class="p">:</span> <span class="s2">&quot;timestamp&quot;</span><span class="p">,</span>
          <span class="nt">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;iso&quot;</span>
        <span class="p">},</span>
        <span class="nt">&quot;data&quot;</span><span class="p">:</span> <span class="p">{</span>
          <span class="nt">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;json&quot;</span>
        <span class="p">},</span>
        <span class="nt">&quot;dimensionExclusions&quot;</span><span class="p">:</span> <span class="p">[</span>
          <span class="s2">&quot;value&quot;</span>
        <span class="p">]</span>
      <span class="p">}</span>
    <span class="p">},</span>
    <span class="nt">&quot;plumber&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;realtime&quot;</span><span class="p">,</span>
      <span class="nt">&quot;windowPeriod&quot;</span><span class="p">:</span> <span class="s2">&quot;PT10m&quot;</span><span class="p">,</span>
      <span class="nt">&quot;segmentGranularity&quot;</span><span class="p">:</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span>
      <span class="nt">&quot;basePersistDirectory&quot;</span><span class="p">:</span> <span class="s2">&quot;\/tmp\/realtime\/basePersist&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">]</span>
</code></pre></div>
<p>This is a JSON Array so you can give more than one realtime stream to a given node. The number you can put in the same process depends on the exact configuration. In general, it is best to think of each realtime stream handler as requiring 2-threads: 1 thread for data consumption and aggregation, 1 thread for incremental persists and other background tasks.</p>

<p>There are four parts to a realtime stream specification, <code>schema</code>, <code>config</code>, <code>firehose</code> and <code>plumber</code> which we will go into here.</p>

<h4 id="schema">Schema</h4>

<p>This describes the data schema for the output Druid segment. More information about concepts in Druid and querying can be found at <a href="Concepts-and-Terminology.html">Concepts-and-Terminology</a> and <a href="Querying.html">Querying</a>.</p>

<table><thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Description</th>
<th>Required</th>
</tr>
</thead><tbody>
<tr>
<td>aggregators</td>
<td>Array of Objects</td>
<td>The list of aggregators to use to aggregate colliding rows together.</td>
<td>yes</td>
</tr>
<tr>
<td>dataSource</td>
<td>String</td>
<td>The name of the dataSource that the segment belongs to.</td>
<td>yes</td>
</tr>
<tr>
<td>indexGranularity</td>
<td>String</td>
<td>The granularity of the data inside the segment. E.g. a value of &quot;minute&quot; will mean that data is aggregated at minutely granularity. That is, if there are collisions in the tuple (minute(timestamp), dimensions), then it will aggregate values together using the aggregators instead of storing individual rows.</td>
<td>yes</td>
</tr>
<tr>
<td>segmentGranularity</td>
<td>String</td>
<td>The granularity of the segment as a whole. This is generally larger than the index granularity and describes the rate at which the realtime server will push segments out for historical servers to take over.</td>
<td>yes</td>
</tr>
<tr>
<td>shardSpec</td>
<td>Object</td>
<td>This describes the shard that is represented by this server. This must be specified properly in order to have multiple realtime nodes indexing the same data stream in a sharded fashion.</td>
<td>no</td>
</tr>
</tbody></table>

<h3 id="config">Config</h3>

<p>This provides configuration for the data processing portion of the realtime stream processor.</p>

<table><thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Description</th>
<th>Required</th>
</tr>
</thead><tbody>
<tr>
<td>intermediatePersistPeriod</td>
<td>ISO8601 Period String</td>
<td>The period that determines the rate at which intermediate persists occur. These persists determine how often commits happen against the incoming realtime stream. If the realtime data loading process is interrupted at time T, it should be restarted to re-read data that arrived at T minus this period.</td>
<td>yes</td>
</tr>
<tr>
<td>maxRowsInMemory</td>
<td>Number</td>
<td>The number of rows to aggregate before persisting. This number is the post-aggregation rows, so it is not equivalent to the number of input events, but the number of aggregated rows that those events result in. This is used to manage the required JVM heap size.</td>
<td>yes</td>
</tr>
</tbody></table>

<h3 id="firehose">Firehose</h3>

<p>See <a href="Firehose.html">Firehose</a>.</p>

<h3 id="plumber">Plumber</h3>

<p>See <a href="Plumber.html">Plumber</a></p>

<h2 id="constraints">Constraints</h2>

<p>The following tables summarizes constraints between settings in the spec file for the Realtime subsystem.</p>

<table><thead>
<tr>
<th>Name</th>
<th>Effect</th>
<th>Minimum</th>
<th>Recommended</th>
</tr>
</thead><tbody>
<tr>
<td>windowPeriod</td>
<td>when reading an InputRow, events with timestamp older than now minus this window are discarded</td>
<td>time jitter tolerance</td>
<td>use this to reject outliers</td>
</tr>
<tr>
<td>segmentGranularity</td>
<td>time granularity (minute, hour, day, week, month) for loading data at query time</td>
<td>equal to indexGranularity</td>
<td>more than indexGranularity</td>
</tr>
<tr>
<td>indexGranularity</td>
<td>time granularity (minute, hour, day, week, month) of indexes</td>
<td>less than segmentGranularity</td>
<td>minute, hour, day, week, month</td>
</tr>
<tr>
<td>intermediatePersistPeriod</td>
<td>the max real time (ISO8601 Period) between flushes of InputRows from memory to disk</td>
<td>avoid excessive flushing</td>
<td>number of un-persisted rows in memory also constrained by maxRowsInMemory</td>
</tr>
<tr>
<td>maxRowsInMemory</td>
<td>the max number of InputRows to hold in memory before a flush to disk</td>
<td>number of un-persisted post-aggregation rows in memory is also constrained by intermediatePersistPeriod</td>
<td>use this to avoid running out of heap if too many rows in an intermediatePersistPeriod</td>
</tr>
</tbody></table>

<p>The normal, expected use cases have the following overall constraints: <code>indexGranularity &lt; intermediatePersistPeriod =&lt; windowPeriod  &lt; segmentGranularity</code></p>

<p>If the RealtimeNode process runs out of heap, try adjusting druid.computation.buffer.size property which specifies a size in bytes that must fit into the heap.</p>

<h2 id="running">Running</h2>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>io.druid.cli.Main server realtime
</code></pre></div>
<h2 id="segment-propagation">Segment Propagation</h2>

<p>The segment propagation diagram for real-time data ingestion can be seen below:</p>

<p><img src="../img/segmentPropagation.png" alt="Segment Propagation" title="Segment Propagation"></p>

<h2 id="requirements">Requirements</h2>

<p>Realtime nodes currently require a Kafka cluster to sit in front of them and collect results. There’s more configuration required for these as well.</p>

<h2 id="extending-the-code">Extending the code</h2>

<p>Realtime integration is intended to be extended in two ways:</p>

<ol>
<li> Connect to data streams from varied systems (<a href="https://github.com/druid-io/druid-api/blob/master/src/main/java/io/druid/data/input/FirehoseFactory.java">Firehose</a>)</li>
<li> Adjust the publishing strategy to match your needs (<a href="https://github.com/metamx/druid/blob/master/server/src/main/java/io/druid/segment/realtime/plumber/PlumberSchool.java">Plumber</a>)</li>
</ol>

<p>The expectations are that the former will be very common and something that users of Druid will do on a fairly regular basis. Most users will probably never have to deal with the latter form of customization. Indeed, we hope that all potential use cases can be packaged up as part of Druid proper without requiring proprietary customization.</p>

<p>Given those expectations, adding a firehose is straightforward and completely encapsulated inside of the interface. Adding a plumber is more involved and requires understanding of how the system works to get right, it’s not impossible, but it’s not intended that individuals new to Druid will be able to do it immediately.</p>

        </div>
        <div class="col-md-3">
          <div class="searchbox">
            <gcse:searchbox-only></gcse:searchbox-only>
          </div>
          <div id="toc" class="nav toc hidden-print">
          </div>
        </div>
      </div>
    </div>

    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/technology">Technology</a>&ensp;·&ensp;
    <a href="/use-cases">Use Cases</a>&ensp;·&ensp;
    <a href="/druid-powered">Powered by Druid</a>&ensp;·&ensp;
    <a href="/docs/latest">Docs</a>&ensp;·&ensp;
    <a href="https://druid.apache.org/community/">Community</a>&ensp;·&ensp;
    <a href="/downloads.html">Download</a>&ensp;·&ensp;
    <a href="/faq">FAQ</a>
    </p>
  </div>
  <div class="text-center">
    <a title="Join the user group" href="https://groups.google.com/forum/#!forum/druid-user" target="_blank"><span class="fa fa-comments"></span></a>&ensp;·&ensp;
    <a title="Follow Druid" href="https://twitter.com/druidio" target="_blank"><span class="fab fa-twitter"></span></a>&ensp;·&ensp;
    <a title="Download via Apache" href="https://www.apache.org/dyn/closer.cgi?path=/incubator/druid/0.14.0-incubating/apache-druid-0.14.0-incubating-bin.tar.gz" target="_blank"><span class="fas fa-feather"></span></a>&ensp;·&ensp;
    <a title="GitHub" href="https://github.com/apache/incubator-druid" target="_blank"><span class="fab fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script>
  function trackDownload(type, url) {
    ga('send', 'event', 'download', type, url);
  }
</script>
<script src="//code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->


    <script>
    $(function() {
      $(".toc").load("/docs/0.6.36/toc.html");

      // There is no way to tell when .gsc-input will be async loaded into the page so just try to set a placeholder until it works
      var tries = 0;
      var timer = setInterval(function() {
        tries++;
        if (tries > 300) clearInterval(timer);
        var searchInput = $('input.gsc-input');
        if (searchInput.length) {
          searchInput.attr('placeholder', 'Search');
          clearInterval(timer);
        }
      }, 100);
    });
    </script>
  </body>
</html>
