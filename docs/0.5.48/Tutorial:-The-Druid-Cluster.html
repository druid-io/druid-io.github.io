<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="druid">

<title>Druid | </title>
<link rel="alternate" type="application/atom+xml" href="/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">

<link href='//fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/bootstrap-pure.css">
<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/header.css">
<link rel="stylesheet" href="/css/footer.css">
<link rel="stylesheet" href="/css/syntax.css">
<link rel="stylesheet" href="/css/docs.css">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>

  <body>
    <!-- Start page_header include -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<div class="top-navigator">
  <div class="container">
    <div class="left-cont">
      <a class="logo" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="right-cont">
      <ul class="links">
        <li class=""><a href="/technology">Technology</a></li>
        <li class=""><a href="/use-cases">Use Cases</a></li>
        <li class=""><a href="/druid-powered">Powered By</a></li>
        <li class=""><a href="/docs/latest/design/">Docs</a></li>
        <li class=""><a href="/community/">Community</a></li>
        <li class=" button-link"><a href="/downloads">Download</a></li>
      </ul>
    </div>
  </div>
  <div class="action-button menu-icon">
    <span class="fa fa-bars"></span> MENU
  </div>
  <div class="action-button menu-icon-close">
    <span class="fa fa-times"></span> MENU
  </div>
</div>

<script type="text/javascript">
  var $menu = $('.right-cont');
  var $menuIcon = $('.menu-icon');
  var $menuIconClose = $('.menu-icon-close');

  function showMenu() {
    $menu.fadeIn(100);
    $menuIcon.fadeOut(100);
    $menuIconClose.fadeIn(100);
  }

  $menuIcon.click(showMenu);

  function hideMenu() {
    $menu.fadeOut(100);
    $menuIconClose.fadeOut(100);
    $menuIcon.fadeIn(100);
  }

  $menuIconClose.click(hideMenu);

  $(window).resize(function() {
    if ($(window).width() >= 840) {
      $menu.fadeIn(100);
      $menuIcon.fadeOut(100);
      $menuIconClose.fadeOut(100);
    }
    else {
      $menu.fadeOut(100);
      $menuIcon.fadeIn(100);
      $menuIconClose.fadeOut(100);
    }
  });
</script>

<!-- Stop page_header include -->


    <div class="container doc-container">
      
      

      
      <p> Looking for the <a href="/docs/0.12.2/">latest stable documentation</a>?</p>
      

      <div class="row">
        <div class="col-md-9 doc-content">
          <p>
            <a class="btn btn-default btn-xs visible-xs-inline-block visible-sm-inline-block" href="#toc">Table of Contents</a>
          </p>
          <p>Welcome back! In our first <a href="https://github.com/metamx/druid/wiki/Tutorial%3A-A-First-Look-at-Druid">tutorial</a>, we introduced you to the most basic Druid setup: a single realtime node. We streamed in some data and queried it. Realtime nodes collect very recent data and periodically hand that data off to the rest of the Druid cluster. Some questions about the architecture must naturally come to mind. What does the rest of Druid cluster look like? How does Druid load available static data?</p>

<p>This tutorial will hopefully answer these questions!</p>

<p>In this tutorial, we will set up other types of Druid nodes as well as and external dependencies for a fully functional Druid cluster. The architecture of Druid is very much like the <a href="http://www.youtube.com/watch?v=7mQuHh1X4H4">Megazord</a> from the popular 90s show Mighty Morphin&#39; Power Rangers. Each Druid node has a specific purpose and the nodes come together to form a fully functional system.</p>

<h2 id="downloading-druid">Downloading Druid</h2>

<p>If you followed the first tutorial, you should already have Druid downloaded. If not, let&#39;s go back and do that first.</p>

<p>You can download the latest version of druid <a href="http://static.druid.io/artifacts/releases/druid-services-0.5.58-bin.tar.gz">here</a></p>

<p>and untar the contents within by issuing:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>tar -zxvf druid-services-*-bin.tar.gz
<span class="nb">cd</span> druid-services-*
</code></pre></div>
<p>You can also <a href="Build-From-Source.html">Build From Source</a>.</p>

<h2 id="external-dependencies">External Dependencies</h2>

<p>Druid requires 3 external dependencies. A &quot;deep&quot; storage that acts as a backup data repository, a relational database such as MySQL to hold configuration and metadata information, and <a href="http://zookeeper.apache.org/">Apache Zookeeper</a> for coordination among different pieces of the cluster.</p>

<p>For deep storage, we have made a public S3 bucket (static.druid.io) available where data for this particular tutorial can be downloaded. More on the data <a href="https://github.com/metamx/druid/wiki/Tutorial-Part-2#the-data">later</a>.</p>

<h3 id="setting-up-mysql">Setting up MySQL</h3>

<ol>
<li>If you don&#39;t already have it, download MySQL Community Server here: <a href="http://dev.mysql.com/downloads/mysql/">http://dev.mysql.com/downloads/mysql/</a></li>
<li>Install MySQL</li>
<li>Create a druid user and database</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>mysql -u root
</code></pre></div><div class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">GRANT</span> <span class="k">ALL</span> <span class="k">ON</span> <span class="n">druid</span><span class="p">.</span><span class="o">*</span> <span class="k">TO</span> <span class="s1">&#39;druid&#39;</span><span class="o">@</span><span class="s1">&#39;localhost&#39;</span> <span class="n">IDENTIFIED</span> <span class="k">BY</span> <span class="s1">&#39;diurd&#39;</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">database</span> <span class="n">druid</span><span class="p">;</span>
</code></pre></div>
<h3 id="setting-up-zookeeper">Setting up Zookeeper</h3>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>curl http://www.motorlogy.com/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz -o zookeeper-3.4.5.tar.gz
tar xzf zookeeper-3.4.5.tar.gz
<span class="nb">cd</span> zookeeper-3.4.5
cp conf/zoo_sample.cfg conf/zoo.cfg
./bin/zkServer.sh start
<span class="nb">cd</span> ..
</code></pre></div>
<h2 id="the-data">The Data</h2>

<p>Similar to the first tutorial, the data we will be loading is based on edits that have occurred on Wikipedia. Every time someone edits a page in Wikipedia, metadata is generated about the editor and edited page. Druid collects each individual event and packages them together in a container known as a <a href="https://github.com/metamx/druid/wiki/Segments">segment</a>. Segments contain data over some span of time. We&#39;ve prebuilt a segment for this tutorial and will cover making your own segments in other <a href="https://github.com/metamx/druid/wiki/Loading-Your-Data">pages</a>.The segment we are going to work with has the following format:</p>

<p>Dimensions (things to filter on):</p>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span><span class="s2">&quot;page&quot;</span>
<span class="s2">&quot;language&quot;</span>
<span class="s2">&quot;user&quot;</span>
<span class="s2">&quot;unpatrolled&quot;</span>
<span class="s2">&quot;newPage&quot;</span>
<span class="s2">&quot;robot&quot;</span>
<span class="s2">&quot;anonymous&quot;</span>
<span class="s2">&quot;namespace&quot;</span>
<span class="s2">&quot;continent&quot;</span>
<span class="s2">&quot;country&quot;</span>
<span class="s2">&quot;region&quot;</span>
<span class="s2">&quot;city&quot;</span>
</code></pre></div>
<p>Metrics (things to aggregate over):</p>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span><span class="s2">&quot;count&quot;</span>
<span class="s2">&quot;added&quot;</span>
<span class="s2">&quot;delta&quot;</span>
<span class="s2">&quot;deleted&quot;</span>
</code></pre></div>
<h2 id="the-cluster">The Cluster</h2>

<p>Let&#39;s start up a few nodes and download our data. First things though, let&#39;s create a config directory where we will store configs for our various nodes:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mkdir config
</code></pre></div>
<p>If you are interested in learning more about Druid configuration files, check out this <a href="https://github.com/metamx/druid/wiki/Configuration">link</a>. Many aspects of Druid are customizable. For the purposes of this tutorial, we are going to use default values for most things.</p>

<h3 id="start-a-master-node">Start a Master Node</h3>

<p>Master nodes are in charge of load assignment and distribution. Master nodes monitor the status of the cluster and command compute nodes to assign and drop segments.</p>

<p>To create the master config file:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mkdir config/master
</code></pre></div>
<p>Under the directory we just created, create the file <code>runtime.properties</code> with the following contents:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>druid.host=127.0.0.1:8082
druid.port=8082
druid.service=master

# logging
com.metamx.emitter.logging=true
com.metamx.emitter.logging.level=info

# zk
druid.zk.service.host=localhost
druid.zk.paths.base=/druid
druid.zk.paths.discoveryPath=/druid/discoveryPath

# aws (demo user)
com.metamx.aws.accessKey=AKIAIMKECRUYKDQGR6YQ
com.metamx.aws.secretKey=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

# db
druid.database.segmentTable=segments
druid.database.user=druid
druid.database.password=diurd
druid.database.connectURI=jdbc:mysql://localhost:3306/druid
druid.database.ruleTable=rules
druid.database.configTable=config

# master runtime configs
druid.master.startDelay=PT60S
</code></pre></div>
<p>To start the master node:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 -classpath lib/*:config/master com.metamx.druid.http.MasterMain
</code></pre></div>
<h3 id="start-a-compute-node">Start a Compute Node</h3>

<p>Compute nodes are the workhorses of a cluster and are in charge of loading historical segments and making them available for queries. Our Wikipedia segment will be downloaded by a compute node.</p>

<p>To create the compute config file:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mkdir config/compute
</code></pre></div>
<p>Under the directory we just created, create the file <code>runtime.properties</code> with the following contents:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>druid.host=127.0.0.1:8081
druid.port=8081
druid.service=compute

# logging
com.metamx.emitter.logging=true
com.metamx.emitter.logging.level=info

# zk
druid.zk.service.host=localhost
druid.zk.paths.base=/druid
druid.zk.paths.discoveryPath=/druid/discoveryPath

# processing
druid.processing.buffer.sizeBytes=10000000

# aws (demo user)
com.metamx.aws.accessKey=AKIAIMKECRUYKDQGR6YQ
com.metamx.aws.secretKey=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

# Path on local FS for storage of segments; dir will be created if needed
druid.paths.indexCache=/tmp/druid/indexCache

# Path on local FS for storage of segment metadata; dir will be created if needed
druid.paths.segmentInfoCache=/tmp/druid/segmentInfoCache

# server
druid.server.maxSize=100000000
</code></pre></div>
<p>To start the compute node:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 -classpath lib/*:config/compute com.metamx.druid.http.ComputeMain
</code></pre></div>
<h3 id="start-a-broker-node">Start a Broker Node</h3>

<p>Broker nodes are responsible for figuring out which compute and/or realtime nodes correspond to which queries. They also merge partial results from these nodes in a scatter/gather fashion.</p>

<p>To create the broker config file:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mkdir config/broker
</code></pre></div>
<p>Under the directory we just created, create the file <code>runtime.properties</code> with the following contents:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>druid.host=127.0.0.1:8080
druid.port=8080
druid.service=broker

# logging
com.metamx.emitter.logging=true
com.metamx.emitter.logging.level=info

# zk
druid.zk.service.host=localhost
druid.zk.paths.base=/druid
druid.zk.paths.discoveryPath=/druid/discoveryPath

# thread pool size for servicing queries
druid.client.http.connections=10
</code></pre></div>
<p>To start the broker node:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 -classpath lib/*:config/broker com.metamx.druid.http.BrokerMain
</code></pre></div>
<h2 id="loading-the-data">Loading the Data</h2>

<p>The MySQL dependency we introduced earlier on contains a &#39;segments&#39; table that contains entries for segments that should be loaded into our cluster. The Druid master compares this table with segments that already exist in the cluster to determine what should be loaded and dropped. To load our wikipedia segment, we need to create an entry in our MySQL segment table.</p>

<p>Usually, when new segments are created, these MySQL entries are created directly so you never have to do this by hand. For this tutorial, we can do this manually by going back into MySQL and issuing:</p>
<div class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="n">use</span> <span class="n">druid</span><span class="p">;</span>
<span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">segments</span> <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="n">dataSource</span><span class="p">,</span> <span class="n">created_date</span><span class="p">,</span> <span class="k">start</span><span class="p">,</span> <span class="k">end</span><span class="p">,</span> <span class="n">partitioned</span><span class="p">,</span> <span class="k">version</span><span class="p">,</span> <span class="n">used</span><span class="p">,</span> <span class="n">payload</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">&#39;wikipedia_2013-08-01T00:00:00.000Z_2013-08-02T00:00:00.000Z_2013-08-08T21:22:48.989Z&#39;</span><span class="p">,</span> <span class="s1">&#39;wikipedia&#39;</span><span class="p">,</span> <span class="s1">&#39;2013-08-08T21:26:23.799Z&#39;</span><span class="p">,</span> <span class="s1">&#39;2013-08-01T00:00:00.000Z&#39;</span><span class="p">,</span> <span class="s1">&#39;2013-08-02T00:00:00.000Z&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;2013-08-08T21:22:48.989Z&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;{\&quot;dataSource\&quot;:\&quot;wikipedia\&quot;,\&quot;interval\&quot;:\&quot;2013-08-01T00:00:00.000Z/2013-08-02T00:00:00.000Z\&quot;,\&quot;version\&quot;:\&quot;2013-08-08T21:22:48.989Z\&quot;,\&quot;loadSpec\&quot;:{\&quot;type\&quot;:\&quot;s3_zip\&quot;,\&quot;bucket\&quot;:\&quot;static.druid.io\&quot;,\&quot;key\&quot;:\&quot;data/segments/wikipedia/20130801T000000.000Z_20130802T000000.000Z/2013-08-08T21_22_48.989Z/0/index.zip\&quot;},\&quot;dimensions\&quot;:\&quot;dma_code,continent_code,geo,area_code,robot,country_name,network,city,namespace,anonymous,unpatrolled,page,postal_code,language,newpage,user,region_lookup\&quot;,\&quot;metrics\&quot;:\&quot;count,delta,variation,added,deleted\&quot;,\&quot;shardSpec\&quot;:{\&quot;type\&quot;:\&quot;none\&quot;},\&quot;binaryVersion\&quot;:9,\&quot;size\&quot;:24664730,\&quot;identifier\&quot;:\&quot;wikipedia_2013-08-01T00:00:00.000Z_2013-08-02T00:00:00.000Z_2013-08-08T21:22:48.989Z\&quot;}&#39;</span><span class="p">);</span>
</code></pre></div>
<p>If you look in your master node logs, you should, after a maximum of a minute or so, see logs of the following form:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>2013-08-08 22:48:41,967 INFO [main-EventThread] com.metamx.druid.master.LoadQueuePeon - Server[/druid/loadQueue/127.0.0.1:8081] done processing [/druid/loadQueue/127.0.0.1:8081/wikipedia_2013-08-01T00:00:00.000Z_2013-08-02T00:00:00.000Z_2013-08-08T21:22:48.989Z]
2013-08-08 22:48:41,969 INFO [ServerInventoryView-0] com.metamx.druid.client.SingleServerInventoryView - Server[127.0.0.1:8081] added segment[wikipedia_2013-08-01T00:00:00.000Z_2013-08-02T00:00:00.000Z_2013-08-08T21:22:48.989Z]
</code></pre></div>
<p>When the segment completes downloading and ready for queries, you should see the following message on your compute node logs:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>2013-08-08 22:48:41,959 INFO [ZkCoordinator-0] com.metamx.druid.coordination.BatchDataSegmentAnnouncer - Announcing segment[wikipedia_2013-08-01T00:00:00.000Z_2013-08-02T00:00:00.000Z_2013-08-08T21:22:48.989Z] at path[/druid/segments/127.0.0.1:8081/2013-08-08T22:48:41.959Z]
</code></pre></div>
<p>At this point, we can query the segment. For more information on querying, see this <a href="https://github.com/metamx/druid/wiki/Querying">link</a>.</p>

<h2 id="next-steps">Next Steps</h2>

<p>Now that you have an understanding of what the Druid clsuter looks like, why not load some of your own data?
Check out the <a href="https://github.com/metamx/druid/wiki/Loading-Your-Data">Loading Your Own Data</a> section for more info!</p>

        </div>
        <div class="col-md-3">
          <div class="searchbox">
            <gcse:searchbox-only></gcse:searchbox-only>
          </div>
          <div id="toc" class="nav toc hidden-print">
          </div>
        </div>
      </div>
    </div>

    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/community/">Community</a>&ensp;·&ensp;
    <a href="/downloads">Download</a>&ensp;·&ensp;
    <a href="/druid-powered">Powered by Druid</a>&ensp;·&ensp;
    <a href="/faq">FAQ</a>&ensp;·&ensp;
    <a href="/licensing">License</a>
    </p>
  </div>
  <div class="text-center">
    <a href="https://groups.google.com/forum/#!forum/druid-user"><span class="fa fa-comments"></span></a>&ensp;·&ensp;
    <a href="https://twitter.com/druidio"><span class="fab fa-twitter"></span></a>&ensp;·&ensp;
    <a href="https://github.com/apache/incubator-druid"><span class="fab fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script src="//code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->


    <script>
    $(function() {
      $(".toc").load("/docs/0.5.48/toc.html");

      // There is no way to tell when .gsc-input will be async loaded into the page so just try to set a placeholder until it works
      var tries = 0;
      var timer = setInterval(function() {
        tries++;
        if (tries > 300) clearInterval(timer);
        var searchInput = $('input.gsc-input');
        if (searchInput.length) {
          searchInput.attr('placeholder', 'Search');
          clearInterval(timer);
        }
      }, 100);
    });
    </script>
  </body>
</html>
