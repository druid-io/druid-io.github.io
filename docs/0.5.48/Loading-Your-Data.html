<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="druid">

<title>Druid | </title>
<link rel="alternate" type="application/atom+xml" href="/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">

<link href='//fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/bootstrap-pure.css">
<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/header.css">
<link rel="stylesheet" href="/css/footer.css">
<link rel="stylesheet" href="/css/syntax.css">
<link rel="stylesheet" href="/css/docs.css">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>

  <body>
    <!-- Start page_header include -->
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

<div class="top-navigator">
  <div class="container">
    <div class="left-cont">
      <a class="logo" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="right-cont">
      <ul class="links">
        <li class=""><a href="/technology">Technology</a></li>
        <li class=""><a href="/use-cases">Use Cases</a></li>
        <li class=""><a href="/druid-powered">Powered By</a></li>
        <li class=""><a href="/docs/latest/design/">Docs</a></li>
        <li class=""><a href="/community/">Community</a></li>
        <li class=" button-link"><a href="/downloads">Download</a></li>
      </ul>
    </div>
  </div>
  <div class="action-button menu-icon">
    <span class="fa fa-bars"></span> MENU
  </div>
  <div class="action-button menu-icon-close">
    <span class="fa fa-times"></span> MENU
  </div>
</div>

<script type="text/javascript">
  var $menu = $('.right-cont');
  var $menuIcon = $('.menu-icon');
  var $menuIconClose = $('.menu-icon-close');

  function showMenu() {
    $menu.fadeIn(100);
    $menuIcon.fadeOut(100);
    $menuIconClose.fadeIn(100);
  }

  $menuIcon.click(showMenu);

  function hideMenu() {
    $menu.fadeOut(100);
    $menuIconClose.fadeOut(100);
    $menuIcon.fadeIn(100);
  }

  $menuIconClose.click(hideMenu);

  $(window).resize(function() {
    if ($(window).width() >= 840) {
      $menu.fadeIn(100);
      $menuIcon.fadeOut(100);
      $menuIconClose.fadeOut(100);
    }
    else {
      $menu.fadeOut(100);
      $menuIcon.fadeIn(100);
      $menuIconClose.fadeOut(100);
    }
  });
</script>

<!-- Stop page_header include -->


    <div class="container doc-container">
      
      

      
      <p> Looking for the <a href="/docs/0.12.2/">latest stable documentation</a>?</p>
      

      <div class="row">
        <div class="col-md-9 doc-content">
          <p>
            <a class="btn btn-default btn-xs visible-xs-inline-block visible-sm-inline-block" href="#toc">Table of Contents</a>
          </p>
          <p>Once you have a realtime node working, it is time to load your own data to see how Druid performs.</p>

<p>Druid can ingest data in three ways: via Kafka and a realtime node, via the indexing service, and via the Hadoop batch loader. Data is ingested in realtime using a <a href="Firehose.html">Firehose</a>.</p>

<h2 id="create-config-directories">Create Config Directories</h2>

<p>Each type of node needs its own config file and directory, so create them as subdirectories under the druid directory.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>mkdir config
mkdir config/realtime
mkdir config/master
mkdir config/compute
mkdir config/broker
</code></pre></div>
<h2 id="loading-data-with-kafka">Loading Data with Kafka</h2>

<p><a href="https://github.com/metamx/druid/blob/druid-0.5.x/realtime/src/main/java/com/metamx/druid/realtime/firehose/KafkaFirehoseFactory.java">KafkaFirehoseFactory</a> is how druid communicates with Kafka. Using this <a href="Firehose.html">Firehose</a> with the right configuration, we can import data into Druid in realtime without writing any code. To load data to a realtime node via Kafka, we&#39;ll first need to initialize Zookeeper and Kafka, and then configure and initialize a <a href="Realtime.html">Realtime</a> node.</p>

<h3 id="booting-kafka">Booting Kafka</h3>

<p>Instructions for booting a Zookeeper and then Kafka cluster are available <a href="http://kafka.apache.org/07/quickstart.html">here</a>.</p>

<ol>
<li>Download Apache Kafka 0.7.2 from <a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  wget http://apache.spinellicreations.com/incubator/kafka/kafka-0.7.2-incubating/kafka-0.7.2-incubating-src.tgz
  tar -xvzf kafka-0.7.2-incubating-src.tgz
  <span class="nb">cd</span> kafka-0.7.2-incubating-src
</code></pre></div>
<ol>
<li>Build Kafka</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  ./sbt update
  ./sbt package
</code></pre></div>
<ol>
<li>Boot Kafka</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  cat config/zookeeper.properties
  bin/zookeeper-server-start.sh config/zookeeper.properties
  <span class="c1"># in a new console</span>
  bin/kafka-server-start.sh config/server.properties
</code></pre></div>
<ol>
<li>Launch the console producer (so you can type in JSON kafka messages in a bit)</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  bin/kafka-console-producer.sh --zookeeper localhost:2181 --topic druidtest
</code></pre></div>
<h3 id="launching-a-realtime-node">Launching a Realtime Node</h3>

<ol>
<li>Create a valid configuration file similar to this called config/realtime/runtime.properties:</li>
</ol>
<div class="highlight"><pre><code class="language-properties" data-lang="properties"><span></span><span class="na">  druid.host</span><span class="o">=</span><span class="s">0.0.0.0:8080</span>
<span class="na">  druid.port</span><span class="o">=</span><span class="s">8080</span>

<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>

<span class="na">  druid.processing.formatString</span><span class="o">=</span><span class="s">processing_%s</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">1</span>
<span class="na">  druid.processing.buffer.sizeBytes</span><span class="o">=</span><span class="s">10000000</span>

  <span class="c">#emitting, opaque marker</span>
<span class="na">  druid.service</span><span class="o">=</span><span class="s">example</span>

<span class="na">  druid.request.logging.dir</span><span class="o">=</span><span class="s">/tmp/example/log</span>
<span class="na">  druid.realtime.specFile</span><span class="o">=</span><span class="s">realtime.spec</span>
<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>
<span class="na">  com.metamx.emitter.logging.level</span><span class="o">=</span><span class="s">debug</span>

  <span class="c"># below are dummy values when operating a realtime only node</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">3</span>

<span class="na">  com.metamx.aws.accessKey</span><span class="o">=</span><span class="s">dummy_access_key</span>
<span class="na">  com.metamx.aws.secretKey</span><span class="o">=</span><span class="s">dummy_secret_key</span>
<span class="na">  druid.pusher.s3.bucket</span><span class="o">=</span><span class="s">dummy_s3_bucket</span>

<span class="na">  druid.zk.service.host</span><span class="o">=</span><span class="s">localhost</span>
<span class="na">  druid.server.maxSize</span><span class="o">=</span><span class="s">300000000000</span>
<span class="na">  druid.zk.paths.base</span><span class="o">=</span><span class="s">/druid</span>
<span class="na">  druid.database.segmentTable</span><span class="o">=</span><span class="s">prod_segments</span>
<span class="na">  druid.database.user</span><span class="o">=</span><span class="s">user</span>
<span class="na">  druid.database.password</span><span class="o">=</span><span class="s">diurd</span>
<span class="na">  druid.database.connectURI</span><span class="o">=</span>
<span class="na">  druid.host</span><span class="o">=</span><span class="s">127.0.0.1:8080</span>
</code></pre></div>
<ol>
<li>Create a valid realtime configuration file similar to this called realtime.spec:</li>
</ol>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span>  <span class="p">[{</span>
    <span class="nt">&quot;schema&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;dataSource&quot;</span><span class="p">:</span><span class="s2">&quot;druidtest&quot;</span><span class="p">,</span>
                 <span class="nt">&quot;aggregators&quot;</span><span class="p">:[</span> <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;impressions&quot;</span><span class="p">},</span>
                                    <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;doubleSum&quot;</span><span class="p">,</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;wp&quot;</span><span class="p">,</span><span class="nt">&quot;fieldName&quot;</span><span class="p">:</span><span class="s2">&quot;wp&quot;</span><span class="p">}],</span>
                 <span class="nt">&quot;indexGranularity&quot;</span><span class="p">:</span><span class="s2">&quot;minute&quot;</span><span class="p">,</span>
             <span class="nt">&quot;shardSpec&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;none&quot;</span> <span class="p">}</span> <span class="p">},</span>
    <span class="nt">&quot;config&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;maxRowsInMemory&quot;</span> <span class="p">:</span> <span class="mi">500000</span><span class="p">,</span>
                 <span class="nt">&quot;intermediatePersistPeriod&quot;</span> <span class="p">:</span> <span class="s2">&quot;PT10m&quot;</span> <span class="p">},</span>
    <span class="nt">&quot;firehose&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;type&quot;</span> <span class="p">:</span> <span class="s2">&quot;kafka-0.7.2&quot;</span><span class="p">,</span>
                   <span class="nt">&quot;consumerProps&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;zk.connect&quot;</span> <span class="p">:</span> <span class="s2">&quot;localhost:2181&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;zk.connectiontimeout.ms&quot;</span> <span class="p">:</span> <span class="s2">&quot;15000&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;zk.sessiontimeout.ms&quot;</span> <span class="p">:</span> <span class="s2">&quot;15000&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;zk.synctime.ms&quot;</span> <span class="p">:</span> <span class="s2">&quot;5000&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;groupid&quot;</span> <span class="p">:</span> <span class="s2">&quot;topic-pixel-local&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;fetch.size&quot;</span> <span class="p">:</span> <span class="s2">&quot;1048586&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;autooffset.reset&quot;</span> <span class="p">:</span> <span class="s2">&quot;largest&quot;</span><span class="p">,</span>
                                       <span class="nt">&quot;autocommit.enable&quot;</span> <span class="p">:</span> <span class="s2">&quot;false&quot;</span> <span class="p">},</span>
                   <span class="nt">&quot;feed&quot;</span> <span class="p">:</span> <span class="s2">&quot;druidtest&quot;</span><span class="p">,</span>
                   <span class="nt">&quot;parser&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;timestampSpec&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;column&quot;</span> <span class="p">:</span> <span class="s2">&quot;utcdt&quot;</span><span class="p">,</span> <span class="nt">&quot;format&quot;</span> <span class="p">:</span> <span class="s2">&quot;iso&quot;</span> <span class="p">},</span>
                                <span class="nt">&quot;data&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;format&quot;</span> <span class="p">:</span> <span class="s2">&quot;json&quot;</span> <span class="p">},</span>
                                <span class="nt">&quot;dimensionExclusions&quot;</span> <span class="p">:</span> <span class="p">[</span><span class="s2">&quot;wp&quot;</span><span class="p">]</span> <span class="p">}</span> <span class="p">},</span>
    <span class="nt">&quot;plumber&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;type&quot;</span> <span class="p">:</span> <span class="s2">&quot;realtime&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;windowPeriod&quot;</span> <span class="p">:</span> <span class="s2">&quot;PT10m&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;segmentGranularity&quot;</span><span class="p">:</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;basePersistDirectory&quot;</span> <span class="p">:</span> <span class="s2">&quot;/tmp/realtime/basePersist&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;rejectionPolicy&quot;</span><span class="p">:</span> <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;messageTime&quot;</span><span class="p">}</span> <span class="p">}</span>

  <span class="p">}]</span>
</code></pre></div>
<ol>
<li>Launch the realtime node</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 <span class="se">\</span>
  -Ddruid.realtime.specFile<span class="o">=</span>config/realtime/realtime.spec <span class="se">\</span>
  -classpath lib/*:config/realtime com.metamx.druid.realtime.RealtimeMain
</code></pre></div>
<ol>
<li>Paste data into the Kafka console producer</li>
</ol>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span>  <span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:01&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}</span>
  <span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:02&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;female&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
  <span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:03&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">3000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">}</span>
  <span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:04&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">4000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;female&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
  <span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:05&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">40</span><span class="p">}</span>
</code></pre></div>
<ol>
<li>Watch the events as they are ingested by Druid&#39;s realtime node</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  ...
  <span class="m">2013</span>-06-17 <span class="m">21</span>:41:55,569 INFO <span class="o">[</span>Global--0<span class="o">]</span> com.metamx.emitter.core.LoggingEmitter - Event <span class="o">[{</span><span class="s2">&quot;feed&quot;</span>:<span class="s2">&quot;metrics&quot;</span>,<span class="s2">&quot;timestamp&quot;</span>:<span class="s2">&quot;2013-06-17T21:41:55.569Z&quot;</span>,<span class="s2">&quot;service&quot;</span>:<span class="s2">&quot;example&quot;</span>,<span class="s2">&quot;host&quot;</span>:<span class="s2">&quot;127.0.0.1&quot;</span>,<span class="s2">&quot;metric&quot;</span>:<span class="s2">&quot;events/processed&quot;</span>,<span class="s2">&quot;value&quot;</span>:5,<span class="s2">&quot;user2&quot;</span>:<span class="s2">&quot;druidtest&quot;</span><span class="o">}]</span>
  ...
</code></pre></div>
<ol>
<li>In a new console, edit a file called query.body:</li>
</ol>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span>  <span class="p">{</span>
      <span class="nt">&quot;queryType&quot;</span><span class="p">:</span> <span class="s2">&quot;groupBy&quot;</span><span class="p">,</span>
      <span class="nt">&quot;dataSource&quot;</span><span class="p">:</span> <span class="s2">&quot;druidtest&quot;</span><span class="p">,</span>
      <span class="nt">&quot;granularity&quot;</span><span class="p">:</span> <span class="s2">&quot;all&quot;</span><span class="p">,</span>
      <span class="nt">&quot;dimensions&quot;</span><span class="p">:</span> <span class="p">[],</span>
      <span class="nt">&quot;aggregations&quot;</span><span class="p">:</span> <span class="p">[</span>
          <span class="p">{</span> <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;rows&quot;</span> <span class="p">},</span>
          <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;longSum&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;imps&quot;</span><span class="p">,</span> <span class="nt">&quot;fieldName&quot;</span><span class="p">:</span> <span class="s2">&quot;impressions&quot;</span><span class="p">},</span>
          <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;doubleSum&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;wp&quot;</span><span class="p">,</span> <span class="nt">&quot;fieldName&quot;</span><span class="p">:</span> <span class="s2">&quot;wp&quot;</span><span class="p">}</span>
      <span class="p">],</span>
      <span class="nt">&quot;intervals&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;2010-01-01T00:00/2020-01-01T00&quot;</span><span class="p">]</span>
  <span class="p">}</span>
</code></pre></div>
<ol>
<li>Submit the query via curl</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  curl -X POST <span class="s2">&quot;http://localhost:8080/druid/v2/?pretty&quot;</span> <span class="se">\</span>
  -H <span class="s1">&#39;content-type: application/json&#39;</span> -d @query.body
</code></pre></div>
<ol>
<li>View Result!</li>
</ol>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span>  <span class="p">[</span> <span class="p">{</span>
    <span class="nt">&quot;timestamp&quot;</span> <span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:00.000Z&quot;</span><span class="p">,</span>
    <span class="nt">&quot;result&quot;</span> <span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;imps&quot;</span> <span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
      <span class="nt">&quot;wp&quot;</span> <span class="p">:</span> <span class="mf">60000.0</span><span class="p">,</span>
      <span class="nt">&quot;rows&quot;</span> <span class="p">:</span> <span class="mi">5</span>
    <span class="p">}</span>
  <span class="p">}</span> <span class="p">]</span>
</code></pre></div>
<p>Now you&#39;re ready for <a href="Querying-Your-Data.html">Querying Your Data</a>!</p>

<h2 id="loading-data-with-the-hadoopdruidindexer">Loading Data with the HadoopDruidIndexer</h2>

<p>Historical data can be loaded via a Hadoop job. </p>

<p>The setup for a single node, &#39;standalone&#39; Hadoop cluster is available at <a href="http://hadoop.apache.org/docs/stable/single_node_setup.html">http://hadoop.apache.org/docs/stable/single_node_setup.html</a>.</p>

<h3 id="setup-mysql">Setup MySQL</h3>

<ol>
<li>If you don&#39;t already have it, download MySQL Community Server here: <a href="http://dev.mysql.com/downloads/mysql/">http://dev.mysql.com/downloads/mysql/</a></li>
<li>Install MySQL</li>
<li>Create a druid user and database</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>mysql -u root
</code></pre></div><div class="highlight"><pre><code class="language-sql" data-lang="sql"><span></span><span class="k">GRANT</span> <span class="k">ALL</span> <span class="k">ON</span> <span class="n">druid</span><span class="p">.</span><span class="o">*</span> <span class="k">TO</span> <span class="s1">&#39;druid&#39;</span><span class="o">@</span><span class="s1">&#39;localhost&#39;</span> <span class="n">IDENTIFIED</span> <span class="k">BY</span> <span class="s1">&#39;diurd&#39;</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">database</span> <span class="n">druid</span><span class="p">;</span>
</code></pre></div>
<p>The <a href="Master.html">Master</a> node will create the tables it needs based on its configuration.</p>

<h3 id="make-sure-you-have-zookeeper-running">Make sure you have ZooKeeper Running</h3>

<p>Make sure that you have a zookeeper instance running.  If you followed the instructions for Kafka, it is probably running.  If you are unsure if you have zookeeper running, try running</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>ps auxww <span class="p">|</span> grep zoo <span class="p">|</span> grep -v grep
</code></pre></div>
<p>If you get any result back, then zookeeper is most likely running.  If you haven&#39;t setup Kafka or do not have zookeeper running, then you can download it and start it up with</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>curl http://www.motorlogy.com/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz -o zookeeper-3.4.5.tar.gz
tar xzf zookeeper-3.4.5.tar.gz
<span class="nb">cd</span> zookeeper-3.4.5
cp conf/zoo_sample.cfg conf/zoo.cfg
./bin/zkServer.sh start
<span class="nb">cd</span> ..
</code></pre></div>
<h3 id="launch-a-master-node">Launch a Master Node</h3>

<p>If you&#39;ve already setup a realtime node, be aware that although you can run multiple node types on one physical computer, you must assign them unique ports. Having used 8080 for the <a href="Realtime.html">Realtime</a> node, we use 8081 for the <a href="Master.html">Master</a>.</p>

<ol>
<li>Setup a configuration file called config/master/runtime.properties similar to:</li>
</ol>
<div class="highlight"><pre><code class="language-properties" data-lang="properties"><span></span><span class="na">  druid.host</span><span class="o">=</span><span class="s">0.0.0.0:8081</span>
<span class="na">  druid.port</span><span class="o">=</span><span class="s">8081</span>

<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>

<span class="na">  druid.processing.formatString</span><span class="o">=</span><span class="s">processing_%s</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">1</span>
<span class="na">  druid.processing.buffer.sizeBytes</span><span class="o">=</span><span class="s">10000000</span>

  <span class="c"># emitting, opaque marker</span>
<span class="na">  druid.service</span><span class="o">=</span><span class="s">example</span>

<span class="na">  druid.master.startDelay</span><span class="o">=</span><span class="s">PT60s</span>
<span class="na">  druid.request.logging.dir</span><span class="o">=</span><span class="s">/tmp/example/log</span>
<span class="na">  druid.realtime.specFile</span><span class="o">=</span><span class="s">realtime.spec</span>
<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>
<span class="na">  com.metamx.emitter.logging.level</span><span class="o">=</span><span class="s">debug</span>

  <span class="c"># below are dummy values when operating a realtime only node</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">3</span>

<span class="na">  com.metamx.aws.accessKey</span><span class="o">=</span><span class="s">dummy_access_key</span>
<span class="na">  com.metamx.aws.secretKey</span><span class="o">=</span><span class="s">dummy_secret_key</span>
<span class="na">  druid.pusher.s3.bucket</span><span class="o">=</span><span class="s">dummy_s3_bucket</span>

<span class="na">  druid.zk.service.host</span><span class="o">=</span><span class="s">localhost</span>
<span class="na">  druid.server.maxSize</span><span class="o">=</span><span class="s">300000000000</span>
<span class="na">  druid.zk.paths.base</span><span class="o">=</span><span class="s">/druid</span>
<span class="na">  druid.database.segmentTable</span><span class="o">=</span><span class="s">prod_segments</span>
<span class="na">  druid.database.user</span><span class="o">=</span><span class="s">druid</span>
<span class="na">  druid.database.password</span><span class="o">=</span><span class="s">diurd</span>
<span class="na">  druid.database.connectURI</span><span class="o">=</span><span class="s">jdbc:mysql://localhost:3306/druid</span>
<span class="na">  druid.zk.paths.discoveryPath</span><span class="o">=</span><span class="s">/druid/discoveryPath</span>
<span class="na">  druid.database.ruleTable</span><span class="o">=</span><span class="s">rules</span>
<span class="na">  druid.database.configTable</span><span class="o">=</span><span class="s">config</span>

  <span class="c"># Path on local FS for storage of segments; dir will be created if needed</span>
<span class="na">  druid.paths.indexCache</span><span class="o">=</span><span class="s">/tmp/druid/indexCache</span>
  <span class="c"># Path on local FS for storage of segment metadata; dir will be created if needed</span>
<span class="na">  druid.paths.segmentInfoCache</span><span class="o">=</span><span class="s">/tmp/druid/segmentInfoCache</span>
</code></pre></div>
<ol>
<li>Launch the <a href="Master.html">Master</a> node</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 <span class="se">\</span>
  -classpath lib/*:config/master <span class="se">\</span>
  com.metamx.druid.http.MasterMain
</code></pre></div>
<h3 id="launch-a-compute-historical-node">Launch a Compute/Historical Node</h3>

<ol>
<li>Create a configuration file in config/compute/runtime.properties similar to:</li>
</ol>
<div class="highlight"><pre><code class="language-properties" data-lang="properties"><span></span><span class="na">  druid.host</span><span class="o">=</span><span class="s">0.0.0.0:8082</span>
<span class="na">  druid.port</span><span class="o">=</span><span class="s">8082</span>

<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>

<span class="na">  druid.processing.formatString</span><span class="o">=</span><span class="s">processing_%s</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">1</span>
<span class="na">  druid.processing.buffer.sizeBytes</span><span class="o">=</span><span class="s">10000000</span>

  <span class="c"># emitting, opaque marker</span>
<span class="na">  druid.service</span><span class="o">=</span><span class="s">example</span>

<span class="na">  druid.request.logging.dir</span><span class="o">=</span><span class="s">/tmp/example/log</span>
<span class="na">  druid.realtime.specFile</span><span class="o">=</span><span class="s">realtime.spec</span>
<span class="na">  com.metamx.emitter.logging</span><span class="o">=</span><span class="s">true</span>
<span class="na">  com.metamx.emitter.logging.level</span><span class="o">=</span><span class="s">debug</span>

  <span class="c"># below are dummy values when operating a realtime only node</span>
<span class="na">  druid.processing.numThreads</span><span class="o">=</span><span class="s">3</span>

<span class="na">  com.metamx.aws.accessKey</span><span class="o">=</span><span class="s">dummy_access_key</span>
<span class="na">  com.metamx.aws.secretKey</span><span class="o">=</span><span class="s">dummy_secret_key</span>
<span class="na">  druid.pusher.s3.bucket</span><span class="o">=</span><span class="s">dummy_s3_bucket</span>

<span class="na">  druid.zk.service.host</span><span class="o">=</span><span class="s">localhost</span>
<span class="na">  druid.server.maxSize</span><span class="o">=</span><span class="s">300000000000</span>
<span class="na">  druid.zk.paths.base</span><span class="o">=</span><span class="s">/druid</span>
<span class="na">  druid.database.segmentTable</span><span class="o">=</span><span class="s">prod_segments</span>
<span class="na">  druid.database.user</span><span class="o">=</span><span class="s">druid</span>
<span class="na">  druid.database.password</span><span class="o">=</span><span class="s">diurd</span>
<span class="na">  druid.database.connectURI</span><span class="o">=</span><span class="s">jdbc:mysql://localhost:3306/druid</span>
<span class="na">  druid.zk.paths.discoveryPath</span><span class="o">=</span><span class="s">/druid/discoveryPath</span>
<span class="na">  druid.database.ruleTable</span><span class="o">=</span><span class="s">rules</span>
<span class="na">  druid.database.configTable</span><span class="o">=</span><span class="s">config</span>

<span class="c"># Path on local FS for storage of segments; dir will be created if needed</span>
<span class="na">  druid.paths.indexCache</span><span class="o">=</span><span class="s">/tmp/druid/indexCache</span>
<span class="c"># Path on local FS for storage of segment metadata; dir will be created if needed</span>
<span class="na">  druid.paths.segmentInfoCache</span><span class="o">=</span><span class="s">/tmp/druid/segmentInfoCache</span>
<span class="c"># Setup local storage mode</span>
<span class="na">  druid.pusher.local.storageDirectory</span><span class="o">=</span><span class="s">/tmp/druid/localStorage</span>
<span class="na">  druid.pusher.local</span><span class="o">=</span><span class="s">true</span>
</code></pre></div>
<ol>
<li>Launch the compute node:</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 <span class="se">\</span>
  -classpath lib/*:config/compute <span class="se">\</span>
  com.metamx.druid.http.ComputeMain
</code></pre></div>
<h3 id="create-a-file-of-records">Create a File of Records</h3>

<p>We can use the same records we have been, in a file called records.json:</p>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span><span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:01&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:02&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;female&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:03&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">3000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:04&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">4000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;female&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;utcdt&quot;</span><span class="p">:</span> <span class="s2">&quot;2010-01-01T01:01:05&quot;</span><span class="p">,</span> <span class="nt">&quot;wp&quot;</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span> <span class="nt">&quot;gender&quot;</span><span class="p">:</span> <span class="s2">&quot;male&quot;</span><span class="p">,</span> <span class="nt">&quot;age&quot;</span><span class="p">:</span> <span class="mi">40</span><span class="p">}</span>
</code></pre></div>
<h3 id="run-the-hadoop-job">Run the Hadoop Job</h3>

<p>Now its time to run the Hadoop <a href="Batch-ingestion.html">Batch-ingestion</a> job, HadoopDruidIndexer, which will fill a historical <a href="Compute.html">Compute</a> node with data. First we&#39;ll need to configure the job.</p>

<ol>
<li>Create a config called batchConfig.json similar to:</li>
</ol>
<div class="highlight"><pre><code class="language-json" data-lang="json"><span></span>  <span class="p">{</span>
    <span class="nt">&quot;dataSource&quot;</span><span class="p">:</span> <span class="s2">&quot;druidtest&quot;</span><span class="p">,</span>
    <span class="nt">&quot;timestampColumn&quot;</span><span class="p">:</span> <span class="s2">&quot;utcdt&quot;</span><span class="p">,</span>
    <span class="nt">&quot;timestampFormat&quot;</span><span class="p">:</span> <span class="s2">&quot;iso&quot;</span><span class="p">,</span>
    <span class="nt">&quot;dataSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span>
      <span class="nt">&quot;dimensions&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="nt">&quot;granularitySpec&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
      <span class="nt">&quot;intervals&quot;</span><span class="p">:[</span><span class="s2">&quot;2010-01-01T01/PT1H&quot;</span><span class="p">],</span>
      <span class="nt">&quot;gran&quot;</span><span class="p">:</span><span class="s2">&quot;hour&quot;</span>
    <span class="p">},</span>
    <span class="nt">&quot;pathSpec&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;static&quot;</span><span class="p">,</span>
                  <span class="nt">&quot;paths&quot;</span><span class="p">:</span> <span class="s2">&quot;/Users/rjurney/Software/druid/records.json&quot;</span> <span class="p">},</span>
    <span class="nt">&quot;rollupSpec&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;aggs&quot;</span><span class="p">:[</span> <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;impressions&quot;</span><span class="p">},</span>
                             <span class="p">{</span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;doubleSum&quot;</span><span class="p">,</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="s2">&quot;wp&quot;</span><span class="p">,</span><span class="nt">&quot;fieldName&quot;</span><span class="p">:</span><span class="s2">&quot;wp&quot;</span><span class="p">}</span>
                             <span class="p">],</span>
                    <span class="nt">&quot;rollupGranularity&quot;</span><span class="p">:</span> <span class="s2">&quot;minute&quot;</span><span class="p">},</span>
    <span class="nt">&quot;workingPath&quot;</span><span class="p">:</span> <span class="s2">&quot;/tmp/working_path&quot;</span><span class="p">,</span>
    <span class="nt">&quot;segmentOutputPath&quot;</span><span class="p">:</span> <span class="s2">&quot;/tmp/segments&quot;</span><span class="p">,</span>
    <span class="nt">&quot;leaveIntermediate&quot;</span><span class="p">:</span> <span class="s2">&quot;false&quot;</span><span class="p">,</span>
    <span class="nt">&quot;partitionsSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;targetPartitionSize&quot;</span><span class="p">:</span> <span class="mi">5000000</span>
    <span class="p">},</span>
    <span class="nt">&quot;updaterJobSpec&quot;</span><span class="p">:</span> <span class="p">{</span>
      <span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="s2">&quot;db&quot;</span><span class="p">,</span>
      <span class="nt">&quot;connectURI&quot;</span><span class="p">:</span><span class="s2">&quot;jdbc:mysql://localhost:3306/druid&quot;</span><span class="p">,</span>
      <span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="s2">&quot;druid&quot;</span><span class="p">,</span>
      <span class="nt">&quot;password&quot;</span><span class="p">:</span><span class="s2">&quot;diurd&quot;</span><span class="p">,</span>
      <span class="nt">&quot;segmentTable&quot;</span><span class="p">:</span><span class="s2">&quot;prod_segments&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
</code></pre></div>
<ol>
<li>Now run the job, with the config pointing at batchConfig.json:</li>
</ol>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span></span>  java -Xmx256m -Duser.timezone<span class="o">=</span>UTC -Dfile.encoding<span class="o">=</span>UTF-8 <span class="se">\</span>
       -Ddruid.realtime.specFile<span class="o">=</span>realtime.spec -classpath lib/* <span class="se">\</span>
       com.metamx.druid.indexer.HadoopDruidIndexerMain batchConfig.json
</code></pre></div>
<p>You can now move on to <a href="Querying-Your-Data.html">Querying Your Data</a>!</p>

        </div>
        <div class="col-md-3">
          <div class="searchbox">
            <gcse:searchbox-only></gcse:searchbox-only>
          </div>
          <div id="toc" class="nav toc hidden-print">
          </div>
        </div>
      </div>
    </div>

    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/community/">Community</a>&ensp;·&ensp;
    <a href="/downloads">Download</a>&ensp;·&ensp;
    <a href="/druid-powered">Powered by Druid</a>&ensp;·&ensp;
    <a href="/faq">FAQ</a>&ensp;·&ensp;
    <a href="/licensing">License</a>
    </p>
  </div>
  <div class="text-center">
    <a href="https://groups.google.com/forum/#!forum/druid-user"><span class="fa fa-comments"></span></a>&ensp;·&ensp;
    <a href="https://twitter.com/druidio"><span class="fab fa-twitter"></span></a>&ensp;·&ensp;
    <a href="https://github.com/apache/incubator-druid"><span class="fab fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script>
  function trackDownload(type, url) {
    ga('send', 'event', 'download', type, url, {'hitCallback':
        function () {
          document.location = url;
        }
    });
  }
</script>
<script src="//code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->


    <script>
    $(function() {
      $(".toc").load("/docs/0.5.48/toc.html");

      // There is no way to tell when .gsc-input will be async loaded into the page so just try to set a placeholder until it works
      var tries = 0;
      var timer = setInterval(function() {
        tries++;
        if (tries > 300) clearInterval(timer);
        var searchInput = $('input.gsc-input');
        if (searchInput.length) {
          searchInput.attr('placeholder', 'Search');
          clearInterval(timer);
        }
      }, 100);
    });
    </script>
  </body>
</html>
