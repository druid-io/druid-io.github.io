<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="druid">

<title>Druid | </title>
<link rel="alternate" type="application/atom+xml" href="http://druid.io/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link rel="stylesheet" href="//static.druid.io/web-assets/bootstrap/3.3.5/css/bootstrap.min.css">

<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/header.css">
<link rel="stylesheet" href="/css/footer.css">
<link rel="stylesheet" href="/css/syntax.css">
<link rel="stylesheet" href="/css/docs.css">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>

  <body>
    <!-- Start page_header include -->
<div class="navbar navbar-inverse navbar-static-top druid-nav">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
        <li class=""><a href="/druid.html">Overview</a></li>
        <li class=""><a href="/downloads.html">Download</a></li>
        <li class=""><a href="/docs/0.12.0/design/index.html">Docs</a></li>
        <li class=""><a href="/community/">Contribute</a></li>
        <li class=""><a href="/blog">Blog</a></li>
        <li><a href="https://twitter.com/druidio/" class="fa fa-twitter"></a></li>
        <li><a href="https://github.com/druid-io/druid/" class="fa fa-github"></a></li>
      </ul>
    </div>
  </div>
</div>
<!-- Stop page_header include -->


    <div class="druid-header">
      <div class="container">
        <h1>Documentation</h1>
        <h4></h4>
      </div>
    </div>

    <div class="container">
      
      
      

      
      <p> Looking for the <a href="/docs/0.12.0/">latest stable documentation</a>?</p>
      

      <div class="row">
        <div class="col-md-9 doc-content">
          <p><a class="btn btn-default btn-xs visible-xs-inline-block visible-sm-inline-block" href="#toc">Table of Contents</a>
          <a class="btn btn-default btn-xs" href="http://static.druid.io/api/0.8.3">API documentation</a></p>
          <h1 id="ingestion-overview">Ingestion Overview</h1>

<p>There are a couple of different ways to get data into Druid. We hope to unify things in the near future, but for the time being
the method you choose to ingest your data into Druid should be driven by your use case.</p>

<h2 id="streaming-data">Streaming Data</h2>

<p>If you have a continuous stream of data, there are a few options to get your data into Druid. It should be noted that the current state of real-time ingestion in Druid does not guarantee exactly once processing. The real-time pipeline is meant to surface insights on
 events as they are occurring. For an accurate copy of ingested data, an accompanying batch pipeline is required. We are working towards a streaming only word, but for
 the time being, we recommend running a lambda architecture.</p>

<h3 id="ingest-from-a-stream-processor">Ingest from a Stream Processor</h3>

<p>If you process your data using a stream processor such as Apache Samza or Apache Storm, you can use the <a href="https://github.com/druid-io/tranquility">Tranquility</a> library to manage
your real-time ingestion. This setup requires using the indexing service for ingestion, which is what is used in production by many organizations that use Druid.</p>

<h3 id="ingest-from-apache-kafka">Ingest from Apache Kafka</h3>

<p>If you wish to ingest directly from Kafka using Tranquility, you will have to write a consumer that reads from Kafka and passes the data to Tranquility.
The other option is to use <a href="../design/realtime.html">standalone Realtime nodes</a>.
It should be noted that standalone realtime nodes use the Kafka high level consumer, which imposes a few restrictions.</p>

<p>Druid replicates segment such that logically equivalent data segments are concurrently hosted on N nodes. If N–1 nodes go down,
the data will still be available for querying. On real-time nodes, this process depends on maintaining logically equivalent
data segments on each of the N nodes, which is not possible with standard Kafka consumer groups if your Kafka topic requires more than one consumer
(because consumers in different consumer groups will split up the data differently).</p>

<p>For example, let&#39;s say your topic is split across Kafka partitions 1, 2, &amp; 3 and you have 2 real-time nodes with linear shard specs 1 &amp; 2.
Both of the real-time nodes are in the same consumer group. Real-time node 1 may consume data from partitions 1 &amp; 3, and real-time node 2 may consume data from partition 2.
Querying for your data through the broker will yield correct results.</p>

<p>The problem arises if you want to replicate your data by creating real-time nodes 3 &amp; 4. These new real-time nodes also
have linear shard specs 1 &amp; 2, and they will consume data from Kafka using a different consumer group. In this case,
real-time node 3 may consume data from partitions 1 &amp; 2, and real-time node 4 may consume data from partition 2.
From Druid&#39;s perspective, the segments hosted by real-time nodes 1 and 3 are the same, and the data hosted by real-time nodes
2 and 4 are the same, although they are reading from different Kafka partitions. Querying for the data will yield inconsistent
results.</p>

<p>Is this always a problem? No. If your data is small enough to fit on a single Kafka partition, you can replicate without issues.
Otherwise, you can run real-time nodes without replication.</p>

<h2 id="large-batch-of-static-data">Large Batch of Static Data</h2>

<p>If you have a large batch of historical data that you want to load all at once into Druid, you should use Druid&#39;s built in support for
 Hadoop-based indexing. Hadoop-based indexing for large (&gt; 1G) of batch data is the fastest way to load data into Druid. If you wish to avoid
 the Hadoop dependency, or if you do not have a Hadoop cluster present, you can look at using the <a href="">index task</a>. The index task will be much slower
 than Hadoop indexing for ingesting batch data.</p>

<p>One pattern that we&#39;ve seen is to store raw events (or processed events) in deep storage (S3, HDFS, etc) and periodically run batch processing jobs over these raw events.
You can, for example, create a directory structure for your raw data, such as the following:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>/prod/&lt;dataSource&gt;/v=1/y=2015/m=03/d=21/H=20/data.gz
/prod/&lt;dataSource&gt;/v=1/y=2015/m=03/d=21/H=21/data.gz
/prod/&lt;dataSource&gt;/v=1/y=2015/m=03/d=21/H=22/data.gz
</code></pre></div>
<p>In this example, hourly raw events are stored in individual gzipped files. Periodic batch processing jobs can then run over these files.</p>

<h2 id="lambda-architecture">Lambda Architecture</h2>

<p>We recommend running a streaming real-time pipeline to run queries over events as they are occurring and a batch pipeline to perform periodic
cleanups of data.</p>

<h2 id="sharding">Sharding</h2>

<p>Multiple segments may exist for the same interval of time for the same datasource. These segments form a <code>block</code> for an interval.
Depending on the type of <code>shardSpec</code> that is used to shard the data, Druid queries may only complete if a <code>block</code> is complete. That is to say, if a block consists of 3 segments, such as:</p>

<p><code>sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_0</code></p>

<p><code>sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_1</code></p>

<p><code>sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_2</code></p>

<p>All 3 segments must be loaded before a query for the interval <code>2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z</code> completes.</p>

<p>The exception to this rule is with using linear shard specs. Linear shard specs do not force &#39;completeness&#39; and queries can complete even if shards are not loaded in the system.
For example, if your real-time ingestion creates 3 segments that were sharded with linear shard spec, and only two of the segments were loaded in the system, queries would return results only for those 2 segments.</p>

        </div>
        <div class="col-md-3">
          <div class="searchbox">
            <gcse:searchbox-only></gcse:searchbox-only>
          </div>
          <div id="toc" class="nav toc hidden-print">
          </div>
        </div>
      </div>
    </div>

    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/community/">Community</a>&ensp;·&ensp;
    <a href="/downloads.html">Download</a>&ensp;·&ensp;
    <a href="/druid-powered.html">Powered by Druid</a>&ensp;·&ensp;
    <a href="/faq.html">FAQ</a>&ensp;·&ensp;
    <a href="/licensing.html">License</a>
    </p>
  </div>
  <div class="text-center">
    <a href="https://groups.google.com/forum/#!forum/druid-user"><span class="fa fa-lg fa-comments"></span></a>&ensp;·&ensp;
    <a href="https://twitter.com/druidio"><span class="fa fa-lg fa-twitter"></span></a>&ensp;·&ensp;
    <a href="https://github.com/druid-io/druid"><span class="fa fa-lg fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script src="http://code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->


    <script>
    $(function() {
      $(".toc").load("/docs/0.8.3/toc.html");

      // There is no way to tell when .gsc-input will be async loaded into the page so just try to set a placeholder until it works
      var tries = 0;
      var timer = setInterval(function() {
        tries++;
        if (tries > 300) clearInterval(timer);
        var searchInput = $('input.gsc-input');
        if (searchInput.length) {
          searchInput.attr('placeholder', 'Search');
          clearInterval(timer);
        }
      }, 100);
    });
    </script>
  </body>
</html>
